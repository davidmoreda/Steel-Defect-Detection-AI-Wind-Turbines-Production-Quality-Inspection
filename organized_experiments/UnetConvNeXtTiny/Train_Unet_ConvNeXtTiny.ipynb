{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Entrenamiento Unet con ConvNeXt Tiny\n",
        "\n",
        "Este cuaderno contiene el 'Script de Rescate', combinando múltiples fases de entrenamiento en un solo flujo consolidado de 100 épocas. ConvNeXt Tiny ofrece un gran balance entre precisión y velocidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instalar librerías necesarias\n",
        "!pip install segmentation-models-pytorch albumentations timm utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.cuda.amp import GradScaler\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "# Configuración Global\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"✅ Usando dispositivo: {DEVICE}\")\n",
        "\n",
        "# Semilla para reproducibilidad\n",
        "def set_seed(seed=42):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "set_seed()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utilidades y Clases del Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# UTILIDADES Y DATASET\n",
        "# ==========================================\n",
        "\n",
        "def rle_decode(mask_rle, shape=(256, 1600)):\n",
        "    '''\n",
        "    Decodifica una máscara en formato RLE (Run Length Encoding) a una imagen binaria.\n",
        "    '''\n",
        "    if pd.isna(mask_rle) or mask_rle == '': return np.zeros(shape, dtype=np.uint8)\n",
        "    s = mask_rle.split()\n",
        "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
        "    starts -= 1\n",
        "    ends = starts + lengths\n",
        "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
        "    for lo, hi in zip(starts, ends):\n",
        "        img[lo:hi] = 1\n",
        "    return img.reshape(shape, order='F')\n",
        "\n",
        "class SeverStalDataset(Dataset):\n",
        "    def __init__(self, img_ids, df, img_dir, transform=None, tile_size=256):\n",
        "        self.img_ids = img_ids\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.tile_size = tile_size\n",
        "        self.rle_dict = {}\n",
        "        \n",
        "        # Agrupar RLEs por imagen\n",
        "        subset_df = df[df['ImageID'].isin(img_ids)]\n",
        "        for img_id, group in subset_df.groupby('ImageID'):\n",
        "            self.rle_dict[img_id] = group[['ClassID', 'EncodedPixels']].values.tolist()\n",
        "\n",
        "    def __len__(self): return len(self.img_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.img_ids[idx]\n",
        "        path = os.path.join(self.img_dir, img_id)\n",
        "        img = cv2.imread(path)\n",
        "        if img is None: \n",
        "            # Placeholder si falla la carga (no debería ocurrir)\n",
        "            return torch.zeros((3, self.tile_size, self.tile_size)), torch.zeros((self.tile_size, self.tile_size)).long()\n",
        "        \n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        h, w = img.shape[:2]\n",
        "\n",
        "        # Crear máscara completa\n",
        "        mask = np.zeros((h, w), dtype=np.uint8)\n",
        "        if img_id in self.rle_dict:\n",
        "            for cls, rle in self.rle_dict[img_id]:\n",
        "                if pd.notna(rle):\n",
        "                    m = rle_decode(rle, shape=(256, 1600)) # Shape original conocida\n",
        "                    mask[m == 1] = int(cls)\n",
        "\n",
        "        # Smart Sampling: Recortar donde hay defecto para entrenar mejor\n",
        "        # Si la imagen tiene defectos, intentamos centrar el crop en uno de ellos\n",
        "        use_defect = False\n",
        "        if mask.max() > 0:\n",
        "            if np.random.rand() < 0.8: # 80% prob de centrar en defecto\n",
        "                use_defect = True\n",
        "\n",
        "        if use_defect:\n",
        "            ys, xs = np.where(mask > 0)\n",
        "            if len(ys) > 0:\n",
        "                center_idx = np.random.randint(len(ys))\n",
        "                cy, cx = ys[center_idx], xs[center_idx]\n",
        "                jitter = self.tile_size // 4\n",
        "                cy += np.random.randint(-jitter, jitter)\n",
        "                cx += np.random.randint(-jitter, jitter)\n",
        "                y1 = np.clip(cy - self.tile_size//2, 0, h - self.tile_size)\n",
        "                x1 = np.clip(cx - self.tile_size//2, 0, w - self.tile_size)\n",
        "            else:\n",
        "                y1 = np.random.randint(0, max(1, h - self.tile_size))\n",
        "                x1 = np.random.randint(0, max(1, w - self.tile_size))\n",
        "        else:\n",
        "            y1 = np.random.randint(0, max(1, h - self.tile_size))\n",
        "            x1 = np.random.randint(0, max(1, w - self.tile_size))\n",
        "\n",
        "        y1, x1 = int(y1), int(x1)\n",
        "        image_crop = img[y1:y1+self.tile_size, x1:x1+self.tile_size]\n",
        "        mask_crop = mask[y1:y1+self.tile_size, x1:x1+self.tile_size]\n",
        "\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image_crop, mask=mask_crop)\n",
        "            image_crop = augmented['image']\n",
        "            mask_crop = augmented['mask']\n",
        "\n",
        "        return image_crop, mask_crop.long()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Métricas y Funciones de Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# MÉTRICAS Y LOOP DE ENTRENAMIENTO\n",
        "# ==========================================\n",
        "\n",
        "def compute_iou(pred, target, num_classes):\n",
        "    ious = []\n",
        "    pred = pred.cpu().numpy()\n",
        "    target = target.cpu().numpy()\n",
        "    for cls in range(num_classes):\n",
        "        pred_cls = (pred == cls)\n",
        "        target_cls = (target == cls)\n",
        "        intersection = np.logical_and(pred_cls, target_cls).sum()\n",
        "        union = np.logical_or(pred_cls, target_cls).sum()\n",
        "        if union == 0: ious.append(float('nan')) \n",
        "        else: ious.append(intersection / union)\n",
        "    return ious\n",
        "\n",
        "def train_one_epoch(model, loader, criterion, optimizer, scaler, device, num_classes):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_ious = []\n",
        "    pbar = tqdm(loader, desc='Training')\n",
        "    \n",
        "    for images, masks in pbar:\n",
        "        images = images.to(device).float()\n",
        "        masks = masks.to(device).long()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        with torch.amp.autocast('cuda'):\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, masks)\n",
        "            \n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            batch_ious = compute_iou(preds, masks, num_classes)\n",
        "            all_ious.append(batch_ious)\n",
        "            \n",
        "        pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
        "        \n",
        "    return total_loss/len(loader), np.nanmean(np.nanmean(all_ious, axis=0)), np.nanmean(all_ious, axis=0)\n",
        "\n",
        "def validate(model, loader, criterion, device, num_classes):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_ious = []\n",
        "    with torch.no_grad():\n",
        "        for images, masks in tqdm(loader, desc='Validation'):\n",
        "            images = images.to(device).float()\n",
        "            masks = masks.to(device).long()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, masks)\n",
        "            total_loss += loss.item()\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            batch_ious = compute_iou(preds, masks, num_classes)\n",
        "            all_ious.append(batch_ious)\n",
        "            \n",
        "    return total_loss/len(loader), np.nanmean(np.nanmean(all_ious, axis=0)), np.nanmean(all_ious, axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuración y Carga de Datos\n",
        "SEVERSTAL_ROOT = '/content/drive/MyDrive/severstal' # Ajustar path según entorno\n",
        "\n",
        "# Transformaciones\n",
        "train_trans = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.2),\n",
        "    A.Normalize(), ToTensorV2()\n",
        "])\n",
        "\n",
        "val_trans = A.Compose([\n",
        "    A.Normalize(), ToTensorV2()\n",
        "])\n",
        "\n",
        "# Cargar CSV (asumiendo existencia)\n",
        "try:\n",
        "    df = pd.read_csv(os.path.join(SEVERSTAL_ROOT, 'train.csv'))\n",
        "    # Preprocesamiento básico del CSV\n",
        "    if 'ImageId_ClassId' in df.columns:\n",
        "        df['ImageID'] = df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n",
        "        df['ClassID'] = df['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\n",
        "    \n",
        "    unique_ids = df['ImageID'].unique().tolist()\n",
        "    train_ids, val_ids = train_test_split(unique_ids, test_size=0.2, random_state=42)\n",
        "    \n",
        "    train_ds = SeverStalDataset(train_ids, df, os.path.join(SEVERSTAL_ROOT, 'train_images'), transform=train_trans)\n",
        "    val_ds = SeverStalDataset(val_ids, df, os.path.join(SEVERSTAL_ROOT, 'train_images'), transform=val_trans)\n",
        "    \n",
        "    train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(val_ds, batch_size=16, shuffle=False, num_workers=2)\n",
        "    print(\"✅ Datos cargados correctamente\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Aviso: No se pudieron cargar los datos ({e}). Asegúrate de tener el dataset.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Definición del Modelo (ConvNeXt Tiny)\n",
        "Nota: Cosine Annealing se usa para bajar el Learning Rate suavemente, permitiendo al modelo afinar pesos en los mínimos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Nota: 'tu-convnext_tiny' requiere la librería timm\n",
        "model = smp.Unet(\n",
        "    encoder_name='tu-convnext_tiny', \n",
        "    encoder_weights='imagenet', \n",
        "    in_channels=3, \n",
        "    classes=5\n",
        ").to(DEVICE)\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-2)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=1e-6)\n",
        "# Loss ponderada para clases difíciles\n",
        "class_weights = torch.tensor([0.1, 2.0, 10.0, 2.0, 2.0]).to(DEVICE)\n",
        "criterion = lambda p, t: 0.4*nn.CrossEntropyLoss(weight=class_weights)(p,t) + 0.3*smp.losses.DiceLoss('multiclass', from_logits=True)(p,t) + 0.3*smp.losses.FocalLoss('multiclass')(p,t)\n",
        "scaler = GradScaler()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bucle de Entrenamiento Consolidado (110 Épocas)\n",
        "Se han unificado las fases de 30, 40 y 30 épocas en un solo bucle robusto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EPOCHS = 110\n",
        "best_iou = 0.0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
        "    t_loss, t_iou, _ = train_one_epoch(model, train_loader, criterion, optimizer, scaler, DEVICE, 5)\n",
        "    v_loss, v_iou, v_ious = validate(model, val_loader, criterion, DEVICE, 5)\n",
        "    \n",
        "    scheduler.step()\n",
        "    \n",
        "    print(f\"Train Loss: {t_loss:.4f} | Val IoU: {v_iou:.4f}\")\n",
        "    print(f\"Detalle IoU por clase: {v_ious}\")\n",
        "    \n",
        "    if v_iou > best_iou:\n",
        "        best_iou = v_iou\n",
        "        torch.save(model.state_dict(), 'convnext_best.pth')\n",
        "        print(\"✅ Récord batido - Modelo guardado\")\n",
        "        \n",
        "    if (epoch+1) % 10 == 0:\n",
        "         torch.save(model.state_dict(), f'convnext_backup_ep{epoch+1}.pth')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
